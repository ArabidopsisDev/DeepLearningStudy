{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d26d5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ff7b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ed30dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0240, -0.1219, -0.1023, -0.0984, -0.0585, -0.0441, -0.0194,  0.2405,\n",
       "          0.1820,  0.0528],\n",
       "        [-0.1372, -0.1390, -0.0409, -0.1883,  0.0394, -0.2026, -0.0270,  0.3177,\n",
       "          0.2407,  0.1200]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa441390",
   "metadata": {},
   "source": [
    "**创建一个块**\n",
    "\n",
    "1. 将输入数据作为其前向传播函数的参数。\n",
    "\n",
    "2. 通过前向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。例如，我们上面模型中的第一个全连接的层接收一个20维的输入，但是返回一个维度为256的输出。\n",
    "\n",
    "3. 计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。\n",
    "\n",
    "4. 存储和访问前向传播计算所需的参数。\n",
    "\n",
    "5. 根据需要初始化模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558da8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        hidden_layer = self.hidden(X)\n",
    "        relu = F.relu(hidden_layer)\n",
    "        output = self.output(relu)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad782cdd",
   "metadata": {},
   "source": [
    "$$ f(\\mathbf{x},\\mathbf{w}) = c \\cdot \\mathbf{w}^\\top \\mathbf{x} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a05fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=True)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        X = self.linear(X)\n",
    "\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218e72d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3481, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe012c7c",
   "metadata": {},
   "source": [
    "**参数管理...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a49e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5059],\n",
       "        [-0.3327]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "\n",
    "X = torch.rand(size=(2, 4))\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec55531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_params(model):\n",
    "    if type(model) == nn.Linear:\n",
    "        nn.init.normal_(model.weight, mean=0, std=.01)\n",
    "        nn.init.zeros_(model.bias)\n",
    "model.apply(init_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
